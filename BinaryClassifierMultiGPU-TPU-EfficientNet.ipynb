{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8441db55",
   "metadata": {},
   "source": [
    "# Binary image classifier with:\n",
    "* TPU / Multi-GPU ready code\n",
    "* Dataset created from directories with separate classes\n",
    "* Preprocessing and augmentation as a Keras layer in dataset preprocessor\n",
    "* Simple baseline CNN\n",
    "* Transfer learning based on Efficient-NET\n",
    "* Builds on:\n",
    "\n",
    "https://www.kaggle.com/code/donkeys/keras-binary-cats-dogs-resnet-98\n",
    "\n",
    "https://towardsdatascience.com/a-comprehensive-guide-to-training-cnns-on-tpu-1beac4b0eb1c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7662dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "import tensorflow as tf\n",
    "import keras_preprocessing\n",
    "from keras_preprocessing import image\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_hub as hub\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f9c86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    # For use with TPU:\n",
    "\n",
    "    # Detect TPUs\n",
    "    \n",
    "    # Locate TPUs on the network\n",
    "    # tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect() # TPU detection\n",
    "    \n",
    "    # TPUStrategy contains the necessary distributed training code that will work on TPUs \n",
    "    # with their 8 compute cores\n",
    "    # strategy = tf.distribute.TPUStrategy(tpu)\n",
    "    \n",
    "    # Multi GPU training\n",
    "    strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\"]) #, \"/gpu:1\"])\n",
    "\n",
    "except ValueError: # If TPU or GPU is not available\n",
    "    strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f578344",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of accelerators: {strategy.num_replicas_in_sync}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a88686",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_IMAGES = './data/PetImages'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92433322",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls $PATH_IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ec0ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32 * strategy.num_replicas_in_sync\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "# This is related to the feature size optimization, a multiple of 128 required for TPU\n",
    "IMG_SIZE = 128 * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7263a837",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_dir = PATH_IMAGES\n",
    "train_val_cat_files = os.listdir(PATH_IMAGES + '/Cat')\n",
    "train_val_dog_files = os.listdir(PATH_IMAGES + '/Dog')\n",
    "\n",
    "# Add a set for final model testing if needed\n",
    "# test_dir = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eca17f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_TOTAL = len(train_val_cat_files) + len(train_val_dog_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96db95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CAT = 'cat'\n",
    "DOG = 'dog'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63443a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "df_data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb47d181",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_TOTAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e7df87",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "idx = 0\n",
    "img_sizes = []\n",
    "file_dir = []\n",
    "files_str = []\n",
    "widths = np.zeros(TRAIN_TOTAL, dtype=int)\n",
    "heights = np.zeros(TRAIN_TOTAL, dtype=int)\n",
    "aspect_ratio = np.zeros(TRAIN_TOTAL)\n",
    "\n",
    "for filename in train_val_cat_files:\n",
    "    labels.append(CAT)\n",
    "    filename_str = f'{PATH_IMAGES}/Cat/{filename}'\n",
    "    files_str.append(filename_str)\n",
    "    # Standardise some old files\n",
    "    img = PIL.Image.open(filename_str).convert('RGB')\n",
    "    file_dir.append(f'{PATH_IMAGES}/Cat/')\n",
    "    img_size = img.size\n",
    "    img_sizes.append(img_size)\n",
    "    widths[idx] = img_size[0]\n",
    "    heights[idx] = img_size[1]\n",
    "    aspect_ratio[idx] = img_size[0]/img_size[1]\n",
    "    \n",
    "    # We can resize already here if we want\n",
    "    #img = img.resize((IMG_SIZE, IMG_SIZE))\n",
    "    #img.save(filename_str)\n",
    "    \n",
    "    idx+=1\n",
    "    \n",
    "for filename in train_val_dog_files:\n",
    "    labels.append(DOG)\n",
    "    filename_str = f'{PATH_IMAGES}/Dog/{filename}'\n",
    "    files_str.append(filename_str)\n",
    "    # Standardise some old files\n",
    "    img = PIL.Image.open(filename_str).convert('RGB')\n",
    "    file_dir.append(f'{PATH_IMAGES}/Dog/')\n",
    "    img_size = img.size\n",
    "    img_sizes.append(img_size)\n",
    "    widths[idx] = img_size[0]\n",
    "    heights[idx] = img_size[1]\n",
    "    aspect_ratio[idx] = img_size[0]/img_size[1]\n",
    "    \n",
    "    # We can resize already here if we want\n",
    "    #img = img.resize((IMG_SIZE, IMG_SIZE))\n",
    "    #img.save(filename_str)\n",
    "    \n",
    "    idx+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1873ad27",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = train_val_cat_files + train_val_dog_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfad5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ccbae6",
   "metadata": {},
   "source": [
    "# Creating dataset dataframe from directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7283b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data['filename'] = file_list\n",
    "df_data['filedir'] = file_dir\n",
    "df_data['cat_or_dog'] = labels\n",
    "df_data['files_str'] = files_str\n",
    "label_encoder = LabelEncoder()\n",
    "df_data['cd_label'] = label_encoder.fit_transform(df_data['cat_or_dog'])\n",
    "df_data[\"size\"] = img_sizes\n",
    "df_data[\"width\"] = widths\n",
    "df_data[\"height\"] = heights\n",
    "df_data[\"aspect_ratio\"] = aspect_ratio\n",
    "# df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84477a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting by aspect ratio to detect some edge case shapes\n",
    "df_sorted = df_data.sort_values(by='aspect_ratio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c074f8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_first_9(df_to_plot):\n",
    "    plt.figure(figsize=[30, 30])\n",
    "    for x in range(9):\n",
    "        filename = df_to_plot.iloc[x]['filename']\n",
    "        path_to_plot = df_to_plot.iloc[x]['filedir'] + df_to_plot.iloc[x]['filename']\n",
    "        img = PIL.Image.open(path_to_plot)\n",
    "        print(filename)\n",
    "        plt.subplot(3, 3, x + 1)\n",
    "        plt.imshow(img)\n",
    "        title_str = filename+\" \"+str(df_to_plot.iloc[x].aspect_ratio)\n",
    "        plt.title(title_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8fc34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_first_9(df_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b497dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping wrong samples\n",
    "df_sorted=df_sorted[:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e245bae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_image(filename):\n",
    "    img = tf.io.read_file(filename)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    img = tf.image.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722f5f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_images_labels(filename, label):\n",
    "    return convert_to_image(filename), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9feb6c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_training(ds, data_augement_fn=None):\n",
    "    ds = ds.map(convert_to_images_labels,\n",
    "               num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "    # Only for datasets fitting in memmory\n",
    "    # ds = ds.cache() # Important to do before data aug\n",
    "    \n",
    "    # Big buffer size preferred\n",
    "    ds = ds.shuffle(buffer_size=2048)\n",
    "    \n",
    "    # Infinite dataset\n",
    "    ds = ds.repeat()\n",
    "    \n",
    "    ds = ds.batch(BATCH_SIZE)\n",
    "    \n",
    "    # Apply data augmentation\n",
    "    if data_augement_fn:\n",
    "        ds = ds.map(data_augement_fn,\n",
    "                   num_parallel_calls=AUTOTUNE)\n",
    "        \n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d705158",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curves(history):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(len(acc))\n",
    "    \n",
    "    plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "    plt.title('Trainig and validation accuracy')\n",
    "    plt.legend(loc=0)\n",
    "    plt.figure();\n",
    "    \n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ba6517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomizing dataframe rows\n",
    "df_sorted=df_sorted.sample(frac=1)\n",
    "df_sorted=df_sorted.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604aa5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e4a4df",
   "metadata": {},
   "source": [
    "# Train val split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1582dbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_split = int(0.25 * len(df_sorted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640dbdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_sorted[:-train_val_split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d523a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = df_sorted[-train_val_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292a2bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files_ds = tf.data.Dataset.from_tensor_slices(df_train['files_str'])\n",
    "val_files_ds = tf.data.Dataset.from_tensor_slices(df_val['files_str'])\n",
    "\n",
    "train_labels_ds = tf.data.Dataset.from_tensor_slices(df_train['cd_label'])\n",
    "val_labels_ds = tf.data.Dataset.from_tensor_slices(df_val['cd_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c865fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list_ds = tf.data.Dataset.zip((train_files_ds, train_labels_ds))\n",
    "\n",
    "val_list_ds = tf.data.Dataset.zip((val_files_ds, val_labels_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c41798b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See a piece of the files dataset with labels\n",
    "for sample in train_list_ds.take(5):\n",
    "    print(sample[0].numpy(), sample[1].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1fa060",
   "metadata": {},
   "source": [
    "# Converting files TF dataset into pictures dataset|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d797d60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = prepare_for_training(train_list_ds)\n",
    "val_ds = prepare_for_training(val_list_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e8b5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ecd342",
   "metadata": {},
   "source": [
    "# For an infinite dataset training (ds.repeat()) one has to set \n",
    "* steps_per_epoch\n",
    "* validation_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980b123e",
   "metadata": {},
   "source": [
    "# Note: remember to tune batch size for TPU and learning rate accordingly to the (large) batch size (not done here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e253038f",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = math.ceil(len(train_list_ds)/BATCH_SIZE)\n",
    "validation_steps = math.ceil(len(val_list_ds)/BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef6bdb4",
   "metadata": {},
   "source": [
    "# A simple baseline CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac5ba41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(show_summary=False):\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        \n",
    "        tf.keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
    "        \n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D(2,2),\n",
    "        \n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D(2,2),\n",
    "        \n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D(2,2),\n",
    "        \n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D(2,2),\n",
    "        \n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dropout(0.5),\n",
    "        \n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    if show_summary:\n",
    "        model.summary()\n",
    "          \n",
    "    model.compile(loss='binary_crossentropy', \n",
    "                  optimizer='adam', \n",
    "                  metrics=['accuracy'],\n",
    "                 steps_per_execution=32)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96039bc4",
   "metadata": {},
   "source": [
    "# Creating model in the distributed strategy scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6c1788",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model = define_model(show_summary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef56161",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62529ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_ds,\n",
    "                   steps_per_epoch=steps_per_epoch,\n",
    "                   epochs=5,\n",
    "                   validation_data=val_ds,\n",
    "                   validation_steps=validation_steps,\n",
    "                   verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cc7a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(val_ds, steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d619c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curves(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379a9ce1",
   "metadata": {},
   "source": [
    "# Training with data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a03d7c",
   "metadata": {},
   "source": [
    "# Data augmentation placed outside model in the data pipeline, because TPU may usually not support augmentation ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7342be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.experimental.preprocessing.RandomFlip('horizontal'),\n",
    "    layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "    layers.experimental.preprocessing.RandomZoom(0.2),\n",
    "    layers.experimental.preprocessing.RandomContrast(factor=0.2),\n",
    "])\n",
    "\n",
    "def data_augment(img, label):\n",
    "    return data_augmentation(img), label\n",
    "\n",
    "train_ds = prepare_for_training(train_list_ds, \n",
    "                               data_augement_fn=data_augment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618b0e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping callback automatically retrieving best weights\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=2,\n",
    "                                                    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a53399",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_ds, \n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    epochs=5, \n",
    "                    validation_data=val_ds,\n",
    "                    validation_steps=validation_steps,\n",
    "                    verbose=1,\n",
    "                    callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa7d69f",
   "metadata": {},
   "source": [
    "# Transfer learning based on EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b717ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TPU has no access to local drive so one has to use uncompressed model\n",
    "# loaded directly to TPU\n",
    "\n",
    "os.environ[\"TFHUB_MODLE_LOAD_FORMAT\"] = \"UNCOMPRESSED\"\n",
    "\n",
    "efficientnet_url = \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_ft1k_b0/classification/2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57600b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_vectors_model(model_url):\n",
    "    feature_extractor_layer = hub.KerasLayer(model_url,\n",
    "                                            trainable=False,\n",
    "                                            name='feature_extraction_layer')\n",
    "    \n",
    "    model = tf.keras.Sequential([\n",
    "        feature_extractor_layer,\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(1, activation='sigmoid', name='output_layer')\n",
    "    ])\n",
    "    \n",
    "    model.build([None, IMG_SIZE, IMG_SIZE, 3])\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                 optimizer='adam',\n",
    "                 metrics=['accuracy'],\n",
    "                 steps_per_execution=32)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e00f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model = create_feature_vectors_model(efficientnet_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446f837a",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_ds,\n",
    "                   steps_per_epoch=steps_per_epoch,\n",
    "                   epochs=3,\n",
    "                   validation_data=val_ds,\n",
    "                   validation_steps=validation_steps,\n",
    "                   verbose=1,\n",
    "                   callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d788d74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f73e0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f381a0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f256906e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01037f94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a46805",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3296a76d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fc5ba7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf39",
   "language": "python",
   "name": "tf39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
