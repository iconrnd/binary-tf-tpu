{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffc13c2f",
   "metadata": {},
   "source": [
    "# Binary image classifier with:\n",
    "* TPU / Multi-GPU ready code\n",
    "* TFRecords dataset created for parallel distributed processing\n",
    "* Dataset created from directories with separate classes\n",
    "* Preprocessing and augmentation as a Keras layer in dataset preprocessor\n",
    "* Transfer learning based on ResNET and EfficientNET\n",
    "\n",
    "* Builds on:\n",
    "\n",
    "https://medium.com/ai%C2%B3-theory-practice-business/image-dataset-with-tfrecord-files-7188b565bfc\n",
    "\n",
    "https://keras.io/examples/keras_recipes/creating_tfrecords/\n",
    "\n",
    "https://www.kaggle.com/code/donkeys/keras-binary-cats-dogs-resnet-98\n",
    "\n",
    "https://towardsdatascience.com/a-comprehensive-guide-to-training-cnns-on-tpu-1beac4b0eb1c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7662dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "import tensorflow as tf\n",
    "import keras_preprocessing\n",
    "from keras_preprocessing import image\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_hub as hub\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "import PIL\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.regularizers import l2\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import (Activation, Dropout, Flatten, Dense, GlobalMaxPooling2D,\n",
    "                         BatchNormalization, Input, Conv2D, GlobalAveragePooling2D)\n",
    "\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f9c86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    # For use with TPU:\n",
    "\n",
    "    # Detect TPUs\n",
    "    \n",
    "    # Locate TPUs on the network\n",
    "    # tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect() # TPU detection\n",
    "    \n",
    "    # TPUStrategy contains the necessary distributed training code that will work on TPUs \n",
    "    # with their 8 compute cores\n",
    "    # strategy = tf.distribute.TPUStrategy(tpu)\n",
    "    \n",
    "    # Multi GPU training\n",
    "    strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\"]) #, \"/gpu:1\"])\n",
    "\n",
    "except ValueError: # If TPU or GPU is not available\n",
    "    strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f578344",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of accelerators: {strategy.num_replicas_in_sync}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e195e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a88686",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_IMAGES = './data/PetImages'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92433322",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls $PATH_IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ec0ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32 * strategy.num_replicas_in_sync\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "# This is related to the feature size optimization, a multiple of 128 required for TPU\n",
    "IMG_SIZE = 128 * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7263a837",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_dir = PATH_IMAGES\n",
    "train_val_cat_files = os.listdir(PATH_IMAGES + '/Cat')\n",
    "train_val_dog_files = os.listdir(PATH_IMAGES + '/Dog')\n",
    "\n",
    "# Add a set for final model testing if needed\n",
    "# test_dir = \n",
    "\n",
    "# Directory where tfrecords will be stored\n",
    "tfrecords_dir = 'tfrecords'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4981658",
   "metadata": {},
   "source": [
    "# Train val split ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eca17f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_TOTAL = len(train_val_cat_files) + len(train_val_dog_files)\n",
    "TRAIN_CNT = int(0.75 * TRAIN_TOTAL)\n",
    "VALID_CNT = TRAIN_TOTAL - TRAIN_CNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96db95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CAT = 'cat'\n",
    "DOG = 'dog'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f5ad6f",
   "metadata": {},
   "source": [
    "# Converting image files dataset to TFRecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789ce92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train val split\n",
    "\n",
    "# Defining how many samples will be stored in a single TFRecords file\n",
    "samples_per_tfrecord = 4096\n",
    "\n",
    "# Training and validation sets\n",
    "tfrecords_cnt_trn = TRAIN_CNT // samples_per_tfrecord\n",
    "tfrecords_cnt_val = VALID_CNT // samples_per_tfrecord\n",
    "\n",
    "# Adding potential remaining samples into one extra TFRecords file\n",
    "if tfrecords_cnt_trn % samples_per_tfrecord:\n",
    "    tfrecords_cnt_trn += 1\n",
    "\n",
    "if tfrecords_cnt_val % samples_per_tfrecord:\n",
    "    tfrecords_cnt_val += 1\n",
    "    \n",
    "if not os.path.exists(tfrecords_dir):\n",
    "    os.makedirs(f'{tfrecords_dir}/train')\n",
    "    os.makedirs(f'{tfrecords_dir}/valid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a569a01",
   "metadata": {},
   "source": [
    "# Defining TFRecords auxilliary routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c903d1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Byte list for storing images\n",
    "def image_feature(value):\n",
    "    return tf.train.Feature(\n",
    "        bytes_list=tf.train.BytesList(value=[tf.io.encode_jpeg(value).numpy()])\n",
    "    )\n",
    "\n",
    "# Inte64 list for storing label integers\n",
    "def int64_feature(value):\n",
    "    return tf.train.Feature(\n",
    "        int64_list=tf.train.Int64List(value=[value])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e55e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_example(image, label):\n",
    "    feature = {\n",
    "        \"image\": image_feature(image),\n",
    "        \"label\": int64_feature(label),\n",
    "    }\n",
    "    \n",
    "    return tf.train.Example(features=tf.train.Features(feature=feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f568eabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decodes example stored in a TFR and returns it as a readable sample\n",
    "def parse_tfrecord_fn(example):\n",
    "    feature_spec = {\n",
    "        \"image\": tf.io.FixedLenFeature([], dtype=tf.string),\n",
    "        \"label\": tf.io.FixedLenFeature([], dtype=tf.int64),\n",
    "    }\n",
    "    \n",
    "    example = tf.io.parse_single_example(example, feature_spec)\n",
    "    example[\"image\"] = tf.io.decode_jpeg(example[\"image\"], channels=3)\n",
    "\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780b6076",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files_list = glob.glob('./data/PetImages/*/*')\n",
    "random.shuffle(all_files_list)\n",
    "\n",
    "# Train val split\n",
    "train_files_list = all_files_list[:TRAIN_CNT]\n",
    "valid_files_list = all_files_list[TRAIN_CNT:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d63b22",
   "metadata": {},
   "source": [
    "# Creating and storing TFRecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3c10ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for tfrec_id in range(tfrecords_cnt_trn):\n",
    "\n",
    "    files_batch = train_files_list[tfrec_id*samples_per_tfrecord:(tfrec_id+1)*samples_per_tfrecord]\n",
    "\n",
    "    with tf.io.TFRecordWriter(\n",
    "        tfrecords_dir + \"/train/tfrecord_%.6i.tfrec\" % (tfrec_id)\n",
    "    ) as writer:\n",
    "    \n",
    "        for i in range(len(files_batch)):\n",
    "    \n",
    "            image = tf.io.decode_jpeg(tf.io.read_file(files_batch[i]))\n",
    "        \n",
    "            if 'Dog' in files_batch[i]:\n",
    "                example = create_example(image, 0)\n",
    "    \n",
    "            elif 'Cat' in files_batch[i]:\n",
    "                example = create_example(image, 1)\n",
    "        \n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "            writer.write(example.SerializeToString())\n",
    "    \n",
    "for tfrec_id in range(tfrecords_cnt_val):\n",
    "\n",
    "    files_batch = valid_files_list[tfrec_id*samples_per_tfrecord:(tfrec_id+1)*samples_per_tfrecord]\n",
    "\n",
    "    with tf.io.TFRecordWriter(\n",
    "        tfrecords_dir + \"/valid/tfrecord_%.6i.tfrec\" % (tfrec_id)\n",
    "    ) as writer:\n",
    "    \n",
    "        for i in range(len(files_batch)):\n",
    "    \n",
    "            image = tf.io.decode_jpeg(tf.io.read_file(files_batch[i]))\n",
    "        \n",
    "            if 'Dog' in files_batch[i]:\n",
    "                example = create_example(image, 0)\n",
    "    \n",
    "            elif 'Cat' in files_batch[i]:\n",
    "                example = create_example(image, 1)\n",
    "        \n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "            writer.write(example.SerializeToString())\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdd6ff6",
   "metadata": {},
   "source": [
    "# Testing raw dataset made out of stored TFRecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d2d7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset = tf.data.TFRecordDataset(\"tfrecords\" + \"/valid/tfrecord_000000.tfrec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d30553",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_dataset = raw_dataset.map(parse_tfrecord_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44297fe4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "parsed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fac4efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for features in parsed_dataset.take(1):\n",
    "    for key in features.keys():\n",
    "        if key != 'image':\n",
    "            print(f'{key}: {features[key]}')\n",
    "            \n",
    "    plt.figure(figsize=[2, 2])\n",
    "    plt.imshow(features['image'].numpy())\n",
    "    plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e016373",
   "metadata": {},
   "source": [
    "# Keras preprocessing layer for the ResNET case and Imagenet dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa379c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.applications.resnet50 import preprocess_input as resnet_preprocess\n",
    "from keras.applications.imagenet_utils import preprocess_input as resnet_preprocess\n",
    "\n",
    "def prepare_sample(features):\n",
    "    image = tf.image.resize(features['image'], size=(IMG_SIZE, IMG_SIZE))\n",
    "    return resnet_preprocess(image), features['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f35eef",
   "metadata": {},
   "source": [
    "# Dataset creation from TFRecords with all auxilliary mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f8496f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(filenames, batch_size, augment_sample_fn=None):\n",
    "    \n",
    "    dataset = (\n",
    "    tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTOTUNE)\n",
    "        .map(parse_tfrecord_fn, num_parallel_calls=AUTOTUNE)\n",
    "        .map(prepare_sample, num_parallel_calls=AUTOTUNE)\n",
    "        .shuffle(10 * batch_size)\n",
    "        .repeat()\n",
    "        .batch(batch_size)\n",
    "    )\n",
    "    \n",
    "    # Apply data augmentation\n",
    "    if augment_sample_fn:\n",
    "        dataset = dataset.map(augment_sample_fn,\n",
    "                   num_parallel_calls=AUTOTUNE)\n",
    "    \n",
    "    dataset = dataset.prefetch(AUTOTUNE)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b775f6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filenames = tf.io.gfile.glob(f'{tfrecords_dir}/train/*.tfrec')\n",
    "valid_filenames = tf.io.gfile.glob(f'{tfrecords_dir}/valid/*.tfrec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d032e710",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46660314",
   "metadata": {},
   "source": [
    "# Plotting a batch from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53566949",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = get_dataset(train_filenames, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63443a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_batch_9(ds):\n",
    "    aux_ds=iter(ds)\n",
    "    #aux_ds.reset()\n",
    "    plt.clf()\n",
    "    plt.figure(figsize=[30, 30])\n",
    "    batch = next(aux_ds)\n",
    "    for n in range(9):\n",
    "        plt.subplot(3, 3, n+1)\n",
    "        plt.imshow(tf.reshape(batch[0][n], (IMG_SIZE, IMG_SIZE, 3)))\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb47d181",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_batch_9(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d705158",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curves(history):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    \n",
    "    epochs = range(len(acc))\n",
    "    \n",
    "    plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "    plt.title('Trainig and validation accuracy')\n",
    "    plt.legend(loc=0)\n",
    "    plt.figure();\n",
    "    \n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ecd342",
   "metadata": {},
   "source": [
    "# For an infinite dataset training (ds.repeat()) one has to set \n",
    "* steps_per_epoch\n",
    "* validation_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980b123e",
   "metadata": {},
   "source": [
    "# Note: remember to tune batch size for TPU and learning rate accordingly to the (large) batch size (not done here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e253038f",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = math.ceil(TRAIN_CNT/BATCH_SIZE)\n",
    "validation_steps = math.ceil(VALID_CNT/BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09b87b9",
   "metadata": {},
   "source": [
    "# ResNET-50 Transfer Learning from TFRecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9791e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9d4a09",
   "metadata": {},
   "source": [
    "* Model creation function allows to specify how many layers are to be kept frozen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac5ba41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(trainable_layers_count, show_summary=False):\n",
    "    \n",
    "    input_tensor = Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    base_model = ResNet50(include_top=False,\n",
    "                         #weights=None,\n",
    "                          weights='imagenet',\n",
    "                         input_tensor=input_tensor)\n",
    "    # base_model.load_weights('./resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
    "    \n",
    "    if trainable_layers_count=='all':\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = True\n",
    "    else:\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = False\n",
    "            \n",
    "        for layer in base_model.layers[-trainable_layers_count:]:\n",
    "            layer.trainable = True\n",
    "        \n",
    "    print('Base model has {} layers'.format(len(base_model.layers)))\n",
    "    \n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(1024, activation='relu', kernel_regularizer=l2(5e-4))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    final_outpu = Dense(1, activation='sigmoid', name='final_output')(x)\n",
    "    \n",
    "    model = Model(input_tensor, final_outpu)\n",
    "    \n",
    "    if show_summary:\n",
    "        model.summary()\n",
    "        \n",
    "    model.compile(loss='binary_crossentropy', \n",
    "                  optimizer='adam', \n",
    "                  metrics=['accuracy'],\n",
    "                 steps_per_execution=32,\n",
    "                 jit_compile=True,)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d4058d",
   "metadata": {},
   "source": [
    "# Creating useful callback functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d905d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import (ModelCheckpoint, LearningRateScheduler, \n",
    "                            EarlyStopping, ReduceLROnPlateau, CSVLogger)\n",
    "\n",
    "checkpoint = ModelCheckpoint('./working/Resnet50_best.h5', monitor='val_loss',\n",
    "                            verbose=1, save_best_only=True, mode='min', save_weights_only=True)\n",
    "\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, \n",
    "                                  verbose=1, mode='auto', epsilon=0.0001)\n",
    "\n",
    "early = EarlyStopping(monitor='val_loss',\n",
    "                      mode='min',\n",
    "                     patience=7)\n",
    "\n",
    "csv_logger = CSVLogger(filename='./working/training_log_csv',\n",
    "                      separator=',',\n",
    "                      append=True)\n",
    "\n",
    "callbacks_list = [checkpoint, csv_logger, early]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e72e716",
   "metadata": {},
   "source": [
    "# Creating model in the distributed strategy scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6c1788",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model = define_model(3, show_summary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e9b8c2",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb07068",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = get_dataset(train_filenames, batch_size)\n",
    "val_ds = get_dataset(valid_filenames, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62529ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "history = model.fit(train_ds,\n",
    "                   steps_per_epoch=steps_per_epoch,\n",
    "                   epochs=6,\n",
    "                   validation_data=val_ds,\n",
    "                   validation_steps=validation_steps,\n",
    "                   verbose=1,\n",
    "                   callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b174acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This loads the best weights stored by the ES callback\n",
    "model.load_weights('./working/Resnet50_best.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cc7a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(val_ds, steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d619c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curves(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9ebcb3",
   "metadata": {},
   "source": [
    "# Training with data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a03d7c",
   "metadata": {},
   "source": [
    "# Data augmentation placed outside model in the data pipeline, TPU may not support augmentation ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f45aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.experimental.preprocessing.RandomFlip('horizontal'),\n",
    "    layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "    layers.experimental.preprocessing.RandomZoom(0.2),\n",
    "    layers.experimental.preprocessing.RandomContrast(factor=0.2),\n",
    "])\n",
    "\n",
    "def data_augment(img, label):\n",
    "    return data_augmentation(img), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7342be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = math.ceil(TRAIN_CNT/BATCH_SIZE)\n",
    "validation_steps = math.ceil(VALID_CNT/BATCH_SIZE)\n",
    "batch_size = 32\n",
    "train_ds = get_dataset(train_filenames, batch_size, augment_sample_fn=data_augment)\n",
    "val_ds = get_dataset(valid_filenames, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618b0e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping callback automatically retrieving best weights\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=4,\n",
    "                                                    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c267e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model = define_model(3, show_summary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a53399",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "history = model.fit(train_ds,\n",
    "                   steps_per_epoch=steps_per_epoch,\n",
    "                   epochs=6,\n",
    "                   validation_data=val_ds,\n",
    "                   validation_steps=validation_steps,\n",
    "                   verbose=1,\n",
    "                   callbacks=[early_stopping_cb])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee23240",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curves(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa7d69f",
   "metadata": {},
   "source": [
    "# Transfer learning based on EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b717ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TFHUB_MODLE_LOAD_FORMAT\"] = \"UNCOMPRESSED\"\n",
    "\n",
    "efficientnet_url = \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_ft1k_b0/classification/2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57600b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_vectors_model(model_url):\n",
    "    feature_extractor_layer = hub.KerasLayer(model_url,\n",
    "                                            trainable=False,\n",
    "                                            name='feature_extraction_layer')\n",
    "    \n",
    "    model = tf.keras.Sequential([\n",
    "        feature_extractor_layer,\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(1, activation='sigmoid', name='output_layer')\n",
    "    ])\n",
    "    \n",
    "    model.build([None, IMG_SIZE, IMG_SIZE, 3])\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                 optimizer='adam',\n",
    "                 metrics=['accuracy'],\n",
    "                 steps_per_execution=32)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e00f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model = create_feature_vectors_model(efficientnet_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446f837a",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_ds,\n",
    "                   steps_per_epoch=steps_per_epoch,\n",
    "                   epochs=3,\n",
    "                   validation_data=val_ds,\n",
    "                   validation_steps=validation_steps,\n",
    "                   verbose=1,\n",
    "                   callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d788d74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f73e0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f381a0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f256906e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01037f94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a46805",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3296a76d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fc5ba7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf39",
   "language": "python",
   "name": "tf39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
