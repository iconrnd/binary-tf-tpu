{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdb2cc54",
   "metadata": {},
   "source": [
    "# Binary image classifier with:\n",
    "* TPU / Multi-GPU ready code\n",
    "* Dataset created from directories with separate classes\n",
    "* Preprocessing and augmentation as a Keras layer in dataset preprocessor\n",
    "* Transfer learning based on ResNET\n",
    "\n",
    "* Builds on:\n",
    "\n",
    "https://www.kaggle.com/code/donkeys/keras-binary-cats-dogs-resnet-98\n",
    "\n",
    "https://towardsdatascience.com/a-comprehensive-guide-to-training-cnns-on-tpu-1beac4b0eb1c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7662dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "import tensorflow as tf\n",
    "import keras_preprocessing\n",
    "from keras_preprocessing import image\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_hub as hub\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "import PIL\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.regularizers import l2\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import (Activation, Dropout, Flatten, Dense, GlobalMaxPooling2D,\n",
    "                         BatchNormalization, Input, Conv2D, GlobalAveragePooling2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f9c86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    # For use with TPU:\n",
    "\n",
    "    # Detect TPUs\n",
    "    \n",
    "    # Locate TPUs on the network\n",
    "    # tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect() # TPU detection\n",
    "    \n",
    "    # TPUStrategy contains the necessary distributed training code that will work on TPUs \n",
    "    # with their 8 compute cores\n",
    "    # strategy = tf.distribute.TPUStrategy(tpu)\n",
    "    \n",
    "    # Multi GPU training\n",
    "    strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\"]) #, \"/gpu:1\"])\n",
    "\n",
    "except ValueError: # If TPU or GPU is not available\n",
    "    strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f578344",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of accelerators: {strategy.num_replicas_in_sync}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e195e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a88686",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_IMAGES = './data/PetImages'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92433322",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls $PATH_IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ec0ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32 * strategy.num_replicas_in_sync\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "# This is related to the feature size optimization, a multiple of 128 required for TPU\n",
    "IMG_SIZE = 128 * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7263a837",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_dir = PATH_IMAGES\n",
    "train_val_cat_files = os.listdir(PATH_IMAGES + '/Cat')\n",
    "train_val_dog_files = os.listdir(PATH_IMAGES + '/Dog')\n",
    "\n",
    "# Add a set for final model testing if needed\n",
    "# test_dir = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eca17f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_TOTAL = len(train_val_cat_files) + len(train_val_dog_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96db95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CAT = 'cat'\n",
    "DOG = 'dog'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63443a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "df_data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb47d181",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_TOTAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e7df87",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "idx = 0\n",
    "img_sizes = []\n",
    "file_dir = []\n",
    "files_str = []\n",
    "widths = np.zeros(TRAIN_TOTAL, dtype=int)\n",
    "heights = np.zeros(TRAIN_TOTAL, dtype=int)\n",
    "aspect_ratio = np.zeros(TRAIN_TOTAL)\n",
    "\n",
    "for filename in train_val_cat_files:\n",
    "    labels.append(CAT)\n",
    "    filename_str = f'{PATH_IMAGES}/Cat/{filename}'\n",
    "    files_str.append(filename_str)\n",
    "    img = PIL.Image.open(filename_str).convert('RGB')\n",
    "    file_dir.append(f'{PATH_IMAGES}/Cat/')\n",
    "    img_size = img.size\n",
    "    img_sizes.append(img_size)\n",
    "    widths[idx] = img_size[0]\n",
    "    heights[idx] = img_size[1]\n",
    "    aspect_ratio[idx] = img_size[0]/img_size[1]\n",
    "    \n",
    "    # We can resize already here if we want\n",
    "    #img = img.resize((IMG_SIZE, IMG_SIZE))\n",
    "    #img.save(filename_str)\n",
    "    \n",
    "    idx+=1\n",
    "    \n",
    "for filename in train_val_dog_files:\n",
    "    labels.append(DOG)\n",
    "    filename_str = f'{PATH_IMAGES}/Dog/{filename}'\n",
    "    files_str.append(filename_str)\n",
    "    img = PIL.Image.open(filename_str).convert('RGB')\n",
    "    file_dir.append(f'{PATH_IMAGES}/Dog/')\n",
    "    img_size = img.size\n",
    "    img_sizes.append(img_size)\n",
    "    widths[idx] = img_size[0]\n",
    "    heights[idx] = img_size[1]\n",
    "    aspect_ratio[idx] = img_size[0]/img_size[1]\n",
    "    \n",
    "    # We can resize already here if we want\n",
    "    #img = img.resize((IMG_SIZE, IMG_SIZE))\n",
    "    #img.save(filename_str)\n",
    "    \n",
    "    idx+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1873ad27",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = train_val_cat_files + train_val_dog_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfad5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc6e386",
   "metadata": {},
   "source": [
    "# Creating dataset dataframe from directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7283b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data['filename'] = file_list\n",
    "df_data['filedir'] = file_dir\n",
    "df_data['cat_or_dog'] = labels\n",
    "df_data['files_str'] = files_str\n",
    "label_encoder = LabelEncoder()\n",
    "df_data['cd_label'] = label_encoder.fit_transform(df_data['cat_or_dog'])\n",
    "df_data[\"size\"] = img_sizes\n",
    "df_data[\"width\"] = widths\n",
    "df_data[\"height\"] = heights\n",
    "df_data[\"aspect_ratio\"] = aspect_ratio\n",
    "# df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84477a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting by aspect ratio to detect some edge case shapes\n",
    "df_sorted = df_data.sort_values(by='aspect_ratio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c074f8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_first_9(df_to_plot):\n",
    "    plt.figure(figsize=[30, 30])\n",
    "    for x in range(9):\n",
    "        filename = df_to_plot.iloc[x]['filename']\n",
    "        path_to_plot = df_to_plot.iloc[x]['filedir'] + df_to_plot.iloc[x]['filename']\n",
    "        img = PIL.Image.open(path_to_plot)\n",
    "        print(filename)\n",
    "        plt.subplot(3, 3, x + 1)\n",
    "        plt.imshow(img)\n",
    "        title_str = filename+\" \"+str(df_to_plot.iloc[x].aspect_ratio)\n",
    "        plt.title(title_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b497dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping wrong samples\n",
    "df_sorted=df_sorted[:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e245bae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_image(filename):\n",
    "    img = tf.io.read_file(filename)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    # ResNET may not need to work with floats\n",
    "    #img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    img = tf.image.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722f5f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_images_labels(filename, label):\n",
    "    return convert_to_image(filename), label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f6f2df",
   "metadata": {},
   "source": [
    "# Keras preprocessing layer for the ResNET case and Imagenet dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c875c0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.applications.resnet50 import preprocess_input as resnet_preprocess\n",
    "from keras.applications.imagenet_utils import preprocess_input as resnet_preprocess\n",
    "\n",
    "def resnet_preprocessor(img, label):\n",
    "    return resnet_preprocess(img), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9feb6c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_training(ds, data_augement_fn=None):\n",
    "    ds = ds.map(convert_to_images_labels,\n",
    "               num_parallel_calls=AUTOTUNE)\n",
    "    \n",
    "    # ResNET-50 preprocessing\n",
    "    \n",
    "    ds = ds.map(resnet_preprocessor,\n",
    "               num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "    # Only for datasets fiting in memmory\n",
    "    # ds = ds.cache() # Important to do before data aug\n",
    "    \n",
    "    # Big buffer size preferred\n",
    "    ds = ds.shuffle(buffer_size=2048)\n",
    "    \n",
    "    # Infinite dataset\n",
    "    ds = ds.repeat()\n",
    "    \n",
    "    ds = ds.batch(BATCH_SIZE)\n",
    "    \n",
    "    # Apply data augmentation\n",
    "    if data_augement_fn:\n",
    "        ds = ds.map(data_augement_fn,\n",
    "                   num_parallel_calls=AUTOTUNE)\n",
    "        \n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d705158",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curves(history):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    \n",
    "    epochs = range(len(acc))\n",
    "    \n",
    "    plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "    plt.title('Trainig and validation accuracy')\n",
    "    plt.legend(loc=0)\n",
    "    plt.figure();\n",
    "    \n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e509a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661694b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomizing dataframe rows\n",
    "df_sorted=df_sorted.sample(frac=1)\n",
    "df_sorted=df_sorted.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1582dbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_split=int(0.25*len(df_sorted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640dbdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=df_sorted[:-train_val_split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d523a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val=df_sorted[-train_val_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292a2bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files_ds = tf.data.Dataset.from_tensor_slices(df_train['files_str'])\n",
    "val_files_ds = tf.data.Dataset.from_tensor_slices(df_val['files_str'])\n",
    "\n",
    "train_labels_ds = tf.data.Dataset.from_tensor_slices(df_train['cd_label'])\n",
    "val_labels_ds = tf.data.Dataset.from_tensor_slices(df_val['cd_label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c865fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list_ds = tf.data.Dataset.zip((train_files_ds, train_labels_ds))\n",
    "\n",
    "val_list_ds = tf.data.Dataset.zip((val_files_ds, val_labels_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c41798b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See a piece of the files dataset with labels\n",
    "for sample in train_list_ds.take(5):\n",
    "    print(sample[0].numpy(), sample[1].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009a043e",
   "metadata": {},
   "source": [
    "# Converting files TF dataset into pictures dataset|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d797d60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = prepare_for_training(train_list_ds)\n",
    "val_ds = prepare_for_training(val_list_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e8b5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534ccce7",
   "metadata": {},
   "source": [
    "# Test preprocessing effect directly from the created dataset batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528b6f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_batch_9(ds):\n",
    "    aux_ds=iter(ds)\n",
    "    plt.clf()\n",
    "    plt.figure(figsize=[30, 30])\n",
    "    batch = next(aux_ds)\n",
    "    for n in range(9):\n",
    "        plt.subplot(3, 3, n+1)\n",
    "        plt.imshow(batch[0][n])\n",
    "        \n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ba932a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_batch_9(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835e5a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ecd342",
   "metadata": {},
   "source": [
    "# For an infinite dataset training (ds.repeat()) one has to set \n",
    "* steps_per_epoch\n",
    "* validation_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980b123e",
   "metadata": {},
   "source": [
    "# Note: remember to tune batch size for TPU and learning rate accordingly to the (large) batch size (not done here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e253038f",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = math.ceil(len(train_list_ds)/BATCH_SIZE)\n",
    "validation_steps = math.ceil(len(val_list_ds)/BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb02d036",
   "metadata": {},
   "source": [
    "# ResNET-50 Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9791e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac1ceb1",
   "metadata": {},
   "source": [
    "* Model creation function allows to specify how many layers are to be kept frozen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac5ba41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(trainable_layers_count, show_summary=False):\n",
    "    \n",
    "    input_tensor = Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    base_model = ResNet50(include_top=False,\n",
    "                         #weights=None,\n",
    "                          weights='imagenet',\n",
    "                         input_tensor=input_tensor)\n",
    "    # base_model.load_weights('./resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
    "    \n",
    "    if trainable_layers_count=='all':\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = True\n",
    "    else:\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = False\n",
    "            \n",
    "        for layer in base_model.layers[-trainable_layers_count:]:\n",
    "            layer.trainable = True\n",
    "        \n",
    "    print('Base model has {} layers'.format(len(base_model.layers)))\n",
    "    \n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(1024, activation='relu', kernel_regularizer=l2(5e-4))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    final_outpu = Dense(1, activation='sigmoid', name='final_output')(x)\n",
    "    \n",
    "    model = Model(input_tensor, final_outpu)\n",
    "    \n",
    "    if show_summary:\n",
    "        model.summary()\n",
    "        \n",
    "    model.compile(loss='binary_crossentropy', \n",
    "                  optimizer='adam', \n",
    "                  metrics=['accuracy'],\n",
    "                 steps_per_execution=32)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7f4de4",
   "metadata": {},
   "source": [
    "# Creating useful callback functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d905d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import (ModelCheckpoint, LearningRateScheduler, \n",
    "                            EarlyStopping, ReduceLROnPlateau, CSVLogger)\n",
    "\n",
    "checkpoint = ModelCheckpoint('./working/Resnet50_best.h5', monitor='val_loss',\n",
    "                            verbose=1, save_best_only=True, mode='min', save_weights_only=True)\n",
    "\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, \n",
    "                                  verbose=1, mode='auto', epsilon=0.0001)\n",
    "\n",
    "early = EarlyStopping(monitor='val_loss',\n",
    "                      mode='min',\n",
    "                     patience=7)\n",
    "\n",
    "csv_logger = CSVLogger(filename='./working/training_log_csv',\n",
    "                      separator=',',\n",
    "                      append=True)\n",
    "\n",
    "callbacks_list = [checkpoint, csv_logger, early]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f529aa3",
   "metadata": {},
   "source": [
    "# Creating model in the distributed strategy scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6c1788",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model = define_model(3, show_summary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68023931",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62529ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_ds,\n",
    "                   steps_per_epoch=steps_per_epoch,\n",
    "                   epochs=5,\n",
    "                   validation_data=val_ds,\n",
    "                   validation_steps=validation_steps,\n",
    "                   verbose=1,\n",
    "                   callbacks=callbacks_list)\n",
    "\n",
    "# This loads the best weights stored by the ES callback\n",
    "model.load_weights('./working/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cc7a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation, here just as an example done on val set\n",
    "model.evaluate(val_ds, steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d619c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curves(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568b790f",
   "metadata": {},
   "source": [
    "# Training with data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a03d7c",
   "metadata": {},
   "source": [
    "# Data augmentation placed outside model in the data pipeline, TPU may not support augmentation ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7342be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.experimental.preprocessing.RandomFlip('horizontal'),\n",
    "    layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "    layers.experimental.preprocessing.RandomZoom(0.2),\n",
    "    layers.experimental.preprocessing.RandomContrast(factor=0.2),\n",
    "])\n",
    "\n",
    "def data_augment(img, label):\n",
    "    return data_augmentation(img), label\n",
    "\n",
    "\n",
    "train_ds = prepare_for_training(train_list_ds, \n",
    "                               data_augement_fn=data_augment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618b0e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping callback automatically retrieving best weights\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=2,\n",
    "                                                    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb97950",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model = define_model(3, show_summary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a53399",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_ds, \n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    epochs=5, \n",
    "                    validation_data=val_ds,\n",
    "                    validation_steps=validation_steps,\n",
    "                    verbose=1,\n",
    "                    callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f73e0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f381a0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f256906e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01037f94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a46805",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3296a76d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fc5ba7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf39",
   "language": "python",
   "name": "tf39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
